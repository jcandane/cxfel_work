{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFYsupGMucrNLqgUI+ZXHl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcandane/cxfel_work/blob/main/NLSA_in_JAX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wrTTC-k8mU4J"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "\n",
        "jax.config.update(\"jax_enable_x64\", True)\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "key = jax.random.PRNGKey(187)\n",
        "\n",
        "@partial(jax.jit, static_argnums=(2,))\n",
        "def diag_convolve2d(A:jax.Array, k:jax.Array, stride:int=1):\n",
        "    \"\"\" 8/17/24\n",
        "    Diagonal-kernel convolution with diagonal components given by k\n",
        "    only sum over the diagonal-intersection, for a given stride.\n",
        "\n",
        "    Arguments:\n",
        "      A:jax.Array -- 2d-initial Array\n",
        "      k:jax.Array -- 1d-diagonal-kernel (e.g. from a purely diagonal 2d-Array)\n",
        "      stride:int  -- stride\n",
        "    Returns:\n",
        "      B:jax.Array -- 2d-diagonally convolved Array\n",
        "    \"\"\"\n",
        "    N, M = A.shape\n",
        "    s    = stride\n",
        "    c    = k.size\n",
        "\n",
        "    x           = int((N - c) // s + 1) ## result size x (hori.)\n",
        "    y           = int((M - c) // s + 1) ## result size y (vert.)\n",
        "    left_over   = (N-c) % s ## on the left-side\n",
        "    window_size = 1 + (y-1)*s ## to stride over\n",
        "    window_x = 1 + (x-1)*s ## to stride over\n",
        "\n",
        "    left_over_y = (M-c) % s ## on the bottom-side\n",
        "\n",
        "    end   = N - left_over\n",
        "    start = end - window_size\n",
        "    B     = k[0] * A[ start:end:s, start:end:s ]\n",
        "    for i in range(1, c):\n",
        "        start-=1\n",
        "        end  -=1\n",
        "        B += k[i]*A[ start:end:s, start:end:s ]\n",
        "    return B\n",
        "\n",
        "from jax.sharding import Mesh, NamedSharding, PartitionSpec as P\n",
        "from jax.experimental import mesh_utils\n",
        "from jax.experimental.shard_map import shard_map\n",
        "\n",
        "import numpy\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def parallel_pair(A, B): ### 7/31/2024\n",
        "\n",
        "    devices = mesh_utils.create_device_mesh((len(jax.devices()), 1), devices=jax.devices())\n",
        "    mesh    = Mesh(devices, axis_names=('i', 'j'))\n",
        "\n",
        "    @jax.jit\n",
        "    def kernel(v_x, v_y, hps=jnp.array([])):\n",
        "        return -2.*jnp.dot(v_x, v_y)\n",
        "\n",
        "    @partial(jax.vmap, in_axes=(None, 0))\n",
        "    def matrix_row(v_x, R_ix):\n",
        "        return kernel(v_x, R_ix) #+ v_x + R_ix ## add v_x[None,:]\n",
        "\n",
        "    @partial(shard_map, mesh=mesh, in_specs=(P('i'), P(None)), out_specs=P('i'))\n",
        "    def batched_pairwise(A_batch, B):\n",
        "        return jax.vmap(matrix_row, in_axes=(0, None))(A_batch, B)\n",
        "\n",
        "    return batched_pairwise(A, B)\n",
        "\n",
        "def sharded_padding(A, l):\n",
        "    \"\"\"\n",
        "    A:jax.Array\n",
        "    l:int (sharding dimension)\n",
        "    GET>\n",
        "    B:jax.Array (such that B.shape[0] % l = 0)\n",
        "    \"\"\"\n",
        "\n",
        "    correction = (l - (A.shape[0] % l)) + A.shape[0]\n",
        "    B = jnp.zeros((correction, A.shape[1]), dtype=A.dtype)\n",
        "    B = B.at[:A.shape[0],:].set(A)\n",
        "    return B\n",
        "\n",
        "######==========\n",
        "def jdist(A, B, Dtype=jnp.float16):\n",
        "\n",
        "    ### move numpy.arrays (on CPU) -> jax.Arrays (on CPU)\n",
        "    R  = jax.device_put(A.astype(Dtype), jax.devices(\"cpu\")[0])\n",
        "    B  = jax.device_put(B.astype(Dtype), jax.devices(\"cpu\")[0])\n",
        "\n",
        "    mesh_    = Mesh(numpy.array(jax.devices()).reshape((len(jax.devices()), 1)), axis_names=('i', 'j'))\n",
        "\n",
        "    def cpu_calculation():\n",
        "        return jnp.sum(R ** 2, axis=1)[:, None] + jnp.sum(B ** 2, axis=1)[None, :]\n",
        "\n",
        "    ### shard & replicate on 4 GPUs version \"_\" jax.Arrays\n",
        "    R_ = jax.device_put(sharded_padding(R, len(jax.devices())), NamedSharding(mesh_, P('i', 'j'))) ### pad then place for both first dimensions....\n",
        "    B_ = jax.device_put(B, NamedSharding(mesh_, P(None)))\n",
        "\n",
        "    D_ij  = cpu_calculation().block_until_ready() ### numpy is too slow, do this operation in jax\n",
        "    D_ij += jax.device_put( parallel_pair(R_, B_).block_until_ready(), jax.devices(\"cpu\")[0])[:R.shape[0],:B.shape[0]]\n",
        "    return numpy.asarray(D_ij)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test data set"
      ],
      "metadata": {
        "id": "L0DFOvEYpU02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "try:\n",
        "    image = Image.open(\"dm_example.png\").convert('1')\n",
        "except:\n",
        "    !wget https://raw.githubusercontent.com/jcandane/cxfel_work/main/dm_example.png #https://github.com/jcandane/cxfel_work/blob/main/dm_example.png\n",
        "    image = Image.open(\"dm_example.png\").convert('1')\n",
        "\n",
        "### EXAMPLE sample random angles [0,180) deg\n",
        "#rotated_image = image.rotate(150.2, fillcolor='#FFF')\n",
        "\n",
        "Image.fromarray( np.array( jnp.array( ( image ) ) ) ) ### to see image need to convert into jax array\n",
        "\n",
        "\n",
        "Θs   = (np.arange(1,36100,1)).astype(int) #(360*np.random.rand(1200)).astype(int)\n",
        "#Θs   = (np.arange(1,181,1)).astype(int) #(360*np.random.rand(1200)).astype(int)\n",
        "R_ix = np.asarray( [ np.asarray( image.rotate(Θ, fillcolor='#FFF') ).reshape(-1) for Θ in Θs ] )\n",
        "R_ix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBp1bxsxme-3",
        "outputId": "a288da47-1f17-47fa-dcd9-4902bba651f9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36099, 16129)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.linalg import eigh\n",
        "import scipy\n",
        "\n",
        "##########################################\n",
        "###### Parameters: R_ix, σ, k=(number of eigenvectors)\n",
        "###### need to build.....iterative diagonalizer\n",
        "##########################################\n",
        "\n",
        "def DiffusionMap(R_ix, k=2, c:int=1, stride:int=1):\n",
        "\n",
        "    ### Compute the pairwise distance matrix\n",
        "    D2 = jdist(R_ix, R_ix) #scipy.spatial.distance.cdist(R_ix, R_ix, 'sqeuclidean')\n",
        "    D2 = diag_convolve2d(D2, jnp.ones(c), stride=stride)\n",
        "    D2 = np.asarray(D2)\n",
        "\n",
        "    ### Choose an appropriate kernel scale parameter (σ)\n",
        "    σ2 = np.mean(D2)\n",
        "\n",
        "    ##### PART of LinearOperator\n",
        "    ### Construct the affinity matrix (kernel)\n",
        "    P = np.exp( - D2 / (2. * σ2))\n",
        "\n",
        "    ### Normalize the affinity matrix (Row-normalization)\n",
        "    row_sums  = np.sum( P, axis=1 )\n",
        "    P        @= np.diag(1.0 / row_sums)\n",
        "    #####\n",
        "\n",
        "    ### Krylov-Subspace Methods\n",
        "    eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(P, k=(1+k))\n",
        "    idx           = np.argsort(eigenvalues)[::-1] ## sort the eigenvalues\n",
        "    eigenvalues  = eigenvalues[idx]\n",
        "    eigenvectors = eigenvectors[:, idx]\n",
        "    embedding    = eigenvectors[:, 1:(1+k)]\n",
        "    return embedding\n",
        "\n",
        "##########################################\n",
        "\n",
        "embedding  = DiffusionMap(R_ix, k=3, c=2)\n",
        "embeddingX = DiffusionMap(R_ix, k=3, c=2, stride=3)\n",
        "\n",
        "# Step 9: Visualize the result\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(embedding[:, 0], embedding[:, 1] , s=1)\n",
        "plt.scatter(embeddingX[:, 0], embeddingX[:, 1] , s=1)\n",
        "plt.title('Diffusion Map Embedding')\n",
        "plt.xlabel('Component 1')\n",
        "plt.ylabel('Component 2')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(np.arange(len(embedding[:, 0])), embedding[:, 0])\n",
        "plt.plot(np.arange(len(embedding[:, 1])), embedding[:, 1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8eAOotH7mfL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j6kmKUUXnlk-"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}